 GestureTalk - Sign Language to Text/Speech Translator  

ðŸ“Œ Project Overview  
GestureTalk is an innovative Human-Computer Interface (HCI) that bridges the communication gap between the deaf/hard-of-hearing community and non-signers. Developed by Team SilentSync( @surajkumarbiswas and @sayanikaraha , this project leverages computer vision and machine learning to translate sign language gestures into real-time text and speech, fostering inclusivity and independence.  

#Key Features  

1. Real-Time Translation:
      Accurately converts ASL (American Sign Language) gestures into text and spoken language with minimal latency.
      Expanded sign recognition to include numbers (0-9) and refined signs for "j" and "z".
2. Multimodal Output:
      Simultaneously displays translated text and provides voice synthesis (via pyttsx3) for versatile communication.
3. User-Friendly Interface:
      Intuitive and simple UI with clear visual feedback, ensuring a smooth and accessible interaction experience.
4. Adaptive Learning:
      Improves translation accuracy over time by dynamically learning and adapting to individual signing nuances.
5. Cross-Platform Compatibility:
    Seamlessly operates across various devices, including smartphones, tablets, and computers, providing ubiquitous access.
6. Backspace Functionality:
    Includes a backspace feature, allowing users to easily correct and erase incorrect predictions, enhancing accuracy and usability.
7. Intelligent Word Suggestions:
    Provides dynamic word suggestions based on previously predicted letters, accelerating the communication process and improving fluency.
8. Multilingual Support:
    Designed to be adaptable to multiple sign languages and spoken languages, making it a globally accessible tool.
9. Improved J and Z recognition:
    Refined the machine learning model to better recognize and translate the signs for the letters "j" and "z".



# signtospeech
